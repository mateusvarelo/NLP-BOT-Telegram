{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "NLP simulador.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao9dVmNjt1HV"
      },
      "source": [
        "# Simulador de PLN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiPK7Y_Zh4I",
        "outputId": "963929c4-f30e-4e07-81eb-3f74278108c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 7.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeIL_ID0HsvM"
      },
      "source": [
        "Você precisa prover o arquivo com os comentários, [daqui](https://www.kaggle.com/luisfredgs/imdb-ptbr), ou utilizar [este notebook](https://www.kaggle.com/tacianotres/kernel68e0f34244), conforme orientado no curso, para que este notebook funcione. O resto é feito automaticamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1OA8z36qqQJ",
        "outputId": "f650716d-5dd1-49c9-a9ff-08d2fac2cd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "import unidecode\n",
        "import pickle\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sklearn.externals\n",
        "import joblib\n",
        "import json\n",
        "import codecs"
      ],
      "metadata": {
        "id": "Sl7Ov1rarDp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjmlo-y7sNPQ",
        "outputId": "e0f62ba0-614a-4c07-c409-4f4b37d71f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/Colab Notebooks/DATA/imdb-reviews-pt-br.csv'\n",
        "file_modelo = '/content/drive/MyDrive/Colab Notebooks/ML-NLP/modelo_analise_sentimento.pkl'\n",
        "\n",
        "file_voca = '/content/drive/MyDrive/Colab Notebooks/ML-NLP/modelo_analise_sentimento_vector.pkl'"
      ],
      "metadata": {
        "id": "pFUQshutq6UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WJomxZlp8Qyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OCiSeQrt1HY"
      },
      "source": [
        "\n",
        "\n",
        "# carrega os dados\n",
        "resenhas = pd.read_csv(file )\n",
        "\n",
        "# ajustando os sentimentos para 0/1\n",
        "resenhas['classificacao'] = resenhas['sentiment'].replace(['neg','pos'], [0,1])\n",
        "\n",
        "# identificando as palavras irrelevantes (stop words)\n",
        "palavras_irrelevantes = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# listando a pontuação\n",
        "pontuacao = list()\n",
        "for ponto in punctuation:\n",
        "    pontuacao.append(ponto)\n",
        "    \n",
        "palavras_irrelevantes_e_pontuacao = pontuacao + palavras_irrelevantes\n",
        "\n",
        "# adicionando casos onde as aspas (simples e duplas) estão no final da frase\n",
        "palavras_irrelevantes_e_pontuacao.append('\".')\n",
        "palavras_irrelevantes_e_pontuacao.append(\"'.\")\n",
        "palavras_irrelevantes_e_pontuacao.append('...')\n",
        "\n",
        "# removendo os acentos\n",
        "palavras_irrelevantes_e_pontuacao_sem_acento = [unidecode.unidecode(sw) for sw in palavras_irrelevantes_e_pontuacao]\n",
        "\n",
        "# tokenizador de frases\n",
        "punct_tokenizer = tokenize.WordPunctTokenizer()\n",
        "\n",
        "# calculador do stemm das palavras\n",
        "stemmer = nltk.RSLPStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69WZqFxHt1Hc"
      },
      "source": [
        "# ajustar as opinioes para o que se espera\n",
        "# reduzindo palavras para o seu stemm; cuidado: bem lento\n",
        "frases_processadas = list()\n",
        "for opiniao in resenhas.text_pt:\n",
        "    nova_opiniao = list()\n",
        "    palavras_opiniao = punct_tokenizer.tokenize(unidecode.unidecode(opiniao.lower()))\n",
        "    for palavra in palavras_opiniao:\n",
        "        if palavra not in palavras_irrelevantes_e_pontuacao_sem_acento:\n",
        "            nova_opiniao.append(stemmer.stem(palavra))\n",
        "    frases_processadas.append(' '.join(nova_opiniao))\n",
        "\n",
        "resenhas['opiniao_tratada'] = frases_processadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM4kSCIpt1Hg"
      },
      "source": [
        "# define uma função para criar um classificador de textos, usando TF-IDF e ngrams 1-2\n",
        "def classificar_texto_tfidf_ngrams(texto, coluna_texto, coluna_classificacao):\n",
        "    vetorizador = TfidfVectorizer(lowercase=False, ngram_range=(1,2))\n",
        "    big_bag_of_words = vetorizador.fit_transform(texto[coluna_texto])\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(big_bag_of_words,\n",
        "                                                        texto[coluna_classificacao],\n",
        "                                                        random_state = 42)\n",
        "\n",
        "    regressao_logistica = LogisticRegression(solver='lbfgs')\n",
        "    regressao_logistica.fit(X_train, Y_train)\n",
        "    \n",
        "    return regressao_logistica.score(X_test, Y_test), \\\n",
        "        regressao_logistica, \\\n",
        "        vetorizador\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# executa a função para criar os objetos\n",
        "acuracia, modelo, vetorizador = classificar_texto_tfidf_ngrams(resenhas, 'opiniao_tratada', 'classificacao')"
      ],
      "metadata": {
        "id": "JQD6uQJWIvAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acuracia #0.8857258390618682"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbIfTlcTApG_",
        "outputId": "cfae047c-2850-4b17-c5ee-35464bef4156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858067124949454"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(modelo, file_modelo)\n",
        "joblib.dump(vetorizador, file_voca)"
      ],
      "metadata": {
        "id": "sDtgEXaMIzP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste"
      ],
      "metadata": {
        "id": "2PCQrDwiIv32"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYDWIyX5t1Hl"
      },
      "source": [
        "# simulador\n",
        "def get_sentindo(modelo, vetorizador, opiniao):\n",
        "    nova_opiniao = list()\n",
        "    palavras_opiniao = tokenize.WordPunctTokenizer().tokenize(unidecode.unidecode(opiniao.lower()))\n",
        "    for palavra in palavras_opiniao:\n",
        "        if palavra not in palavras_irrelevantes_e_pontuacao_sem_acento:\n",
        "            nova_opiniao.append(stemmer.stem(palavra))\n",
        "    opiniao_filtrada = ' '.join(nova_opiniao)\n",
        "\n",
        " \n",
        "    big_bag_of_words = vetorizador.transform([opiniao_filtrada])\n",
        " \n",
        "    return 'Seu comentario é positivo :)' if  (modelo.predict(big_bag_of_words)[0] == 1) else 'Seu comentario é negativo (:'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_modelo_vecto():\n",
        "    modelo_load  = joblib.load(file_modelo)\n",
        "    vetor =joblib.load(file_voca)\n",
        "    return modelo_load , \\\n",
        "          vetor\n"
      ],
      "metadata": {
        "id": "dyoBKPOntpe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo , vetor = get_modelo_vecto()\n",
        "\n"
      ],
      "metadata": {
        "id": "lkqW_f9I6sVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pROtUNRbt1Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c311cb3-b53b-4412-912b-4ba991c0b3bf"
      },
      "source": [
        "\n",
        "\n",
        "opiniao = str(input('Sua opnião:'))\n",
        "print('Sua frase:',opiniao)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sua opnião:Tu é Brabo\n",
            "Sua frase: Tu é Brabo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFmC2PhMt1Ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fa5cbe-f221-4afa-d308-afb28b8ff31c"
      },
      "source": [
        "print( get_sentindo(modelo,vetor , opiniao))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seu comentario é positivo :)\n"
          ]
        }
      ]
    }
  ]
}